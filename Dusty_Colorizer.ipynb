{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import colorizerutils as utils\n",
    "from IPython.display import Video\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import losses\n",
    "from tensorflow.keras import metrics\n",
    "from tensorflow.keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.8.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The amount of GPU memory to allocate to Tensorflow\n",
    "vram = 14 # GB\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "\n",
    "tf.config.set_logical_device_configuration(\n",
    "    gpus[0],\n",
    "    [tf.config.LogicalDeviceConfiguration(memory_limit=vram*1024)])\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataset using images from ../images/train_images/\n",
    "train_dataset = tf.data.Dataset.from_generator(\n",
    "    lambda: utils.image_loader('../shows/trainepisodes/'),\n",
    "    output_types=(tf.float32,tf.float32)\n",
    ")\n",
    "\n",
    "# Directory for tensorboard logs\n",
    "log_directory = 'logs/'\n",
    "\n",
    "# Set up tensorboard logging for the generator and discriminator loss\n",
    "summary_writer = tf.summary.create_file_writer(log_directory + 'dusty/')\n",
    "gen_loss_tracker = metrics.Mean('Generator_loss',dtype=tf.float32)\n",
    "gen_adv_tracker = metrics.Mean('Generator_adversarial_loss',dtype=tf.float32)\n",
    "gen_mse_tracker = metrics.Mean('Generator_mse_loss',dtype=tf.float32)\n",
    "disc_loss_tracker = metrics.Mean('Discriminator_loss',dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsampling block for use in generator and discriminator\n",
    "def downsampling(filters,stride,prev_layer):\n",
    "\n",
    "    init = initializers.RandomNormal()\n",
    "\n",
    "    block = layers.Conv2D(filters,strides=stride,kernel_size=4,padding='same',kernel_initializer=init,use_bias=False)(prev_layer)\n",
    "    block = layers.BatchNormalization()(block)\n",
    "    block = layers.LeakyReLU(0.2)(block)\n",
    "\n",
    "    return block\n",
    "\n",
    "# Upsampling block for use in generator only\n",
    "# Skip layer should be the same shape as the output to the transpose convolutional layer\n",
    "# Or twice the size of the prev_layer input\n",
    "def upsampling(filters,stride,prev_layer,skip_layer):\n",
    "\n",
    "    init = initializers.RandomNormal()\n",
    "\n",
    "    block = layers.Conv2DTranspose(\n",
    "        filters,strides=stride,kernel_size=4,padding='same',kernel_initializer=init,use_bias=False)(prev_layer)\n",
    "    block = layers.BatchNormalization()(block)\n",
    "    block = layers.Concatenate()([block,skip_layer])\n",
    "    block = layers.LeakyReLU(0.2)(block)\n",
    "    block = layers.Dropout(0.3)(block)\n",
    "\n",
    "    return block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_generator():\n",
    "\n",
    "    init = initializers.RandomNormal()\n",
    "\n",
    "    # Model input is a (64x64) grayscale image\n",
    "    model_input = layers.Input(shape=(64,64,1))\n",
    "\n",
    "    # Downsampling stack\n",
    "    down0 = downsampling(filters=32,stride=1,prev_layer=model_input) # (64x64) -> (64x64)\n",
    "    down1 = downsampling(64,2,down0) # (64x64) -> (32x32)\n",
    "    down2 = downsampling(128,2,down1) # (32x32) -> (16x16)\n",
    "    down3 = downsampling(256,2,down2) # (16x16) -> (8x8)\n",
    "    down4 = downsampling(256,2,down3) # (8x8) -> (4x4)\n",
    "    down5 = downsampling(256,2,down4) # (4x4) -> (2x2)\n",
    "    down6 = downsampling(256,2,down5) # (2x2) -> (1x1)\n",
    "\n",
    "\n",
    "    # Upsampling stack\n",
    "    up5 = upsampling(filters=256,stride=2,prev_layer=down6,skip_layer=down5) # (1x1) -> (2x2)\n",
    "    up4 = upsampling(256,2,up5,down4) # (2x2) -> (4x4)\n",
    "    up3 = upsampling(256,2,up4,down3) # (4x4) -> (8x8)\n",
    "    up2 = upsampling(128,2,up3,down2) # (8x8) -> (16x16)\n",
    "    up1 = upsampling(64,2,up2,down1) # (16x16) -> (32x32)\n",
    "    up0 = upsampling(32,2,up1,down0) # (32x32) -> (64x64)\n",
    "    \n",
    "    # Model output is (64x64) with 2 color channels with values between -1 and 1\n",
    "    model_output = layers.Conv2DTranspose(\n",
    "        2,strides=1,kernel_size=4,padding='same',activation='tanh',kernel_initializer=init,use_bias=False)(up0)\n",
    "\n",
    "    model = keras.models.Model(model_input,model_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_loss(disc_output_generated,generator_output,color_channels):\n",
    "\n",
    "    # Part of the loss is based on the discriminator output on fake images\n",
    "    cross_entropy = losses.BinaryCrossentropy(from_logits=True,label_smoothing=0.1)\n",
    "\n",
    "    # Part of the loss (scaled) is based on the difference between the\n",
    "    # generated images and the original colored images\n",
    "    mse = losses.MeanSquaredError()\n",
    "    mse_scaler = 25\n",
    "\n",
    "    # Generator wants the discriminator to classify the generated images as 1 (real)\n",
    "    # Adersarial loss is the defference between all 1s and the actual discriminator output\n",
    "    adversarial_loss = cross_entropy(tf.ones_like(disc_output_generated),disc_output_generated)\n",
    "    mse_loss = mse(generator_output,color_channels) \n",
    "\n",
    "    # Return all three losses for tensorboard\n",
    "    return adversarial_loss + (mse_scaler * mse_loss), adversarial_loss, mse_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 64, 64, 32)   512         ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 64, 64, 32)  128         ['conv2d[0][0]']                 \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " leaky_re_lu (LeakyReLU)        (None, 64, 64, 32)   0           ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 32, 32, 64)   32768       ['leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 32, 32, 64)  256         ['conv2d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_1 (LeakyReLU)      (None, 32, 32, 64)   0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 16, 16, 128)  512        ['conv2d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_2 (LeakyReLU)      (None, 16, 16, 128)  0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_3[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_3 (LeakyReLU)      (None, 8, 8, 256)    0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 4, 4, 256)    1048576     ['leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_4 (LeakyReLU)      (None, 4, 4, 256)    0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 2, 2, 256)    1048576     ['leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 2, 2, 256)   1024        ['conv2d_5[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_5 (LeakyReLU)      (None, 2, 2, 256)    0           ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 1, 1, 256)    1048576     ['leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 1, 1, 256)   1024        ['conv2d_6[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " leaky_re_lu_6 (LeakyReLU)      (None, 1, 1, 256)    0           ['batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_transpose (Conv2DTransp  (None, 2, 2, 256)   1048576     ['leaky_re_lu_6[0][0]']          \n",
      " ose)                                                                                             \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 2, 2, 256)   1024        ['conv2d_transpose[0][0]']       \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 2, 2, 512)    0           ['batch_normalization_7[0][0]',  \n",
      "                                                                  'leaky_re_lu_5[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_7 (LeakyReLU)      (None, 2, 2, 512)    0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2, 2, 512)    0           ['leaky_re_lu_7[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_1 (Conv2DTran  (None, 4, 4, 256)   2097152     ['dropout[0][0]']                \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_8 (BatchNo  (None, 4, 4, 256)   1024        ['conv2d_transpose_1[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 4, 4, 512)    0           ['batch_normalization_8[0][0]',  \n",
      "                                                                  'leaky_re_lu_4[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_8 (LeakyReLU)      (None, 4, 4, 512)    0           ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 4, 4, 512)    0           ['leaky_re_lu_8[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_2 (Conv2DTran  (None, 8, 8, 256)   2097152     ['dropout_1[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 8, 8, 256)   1024        ['conv2d_transpose_2[0][0]']     \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 8, 8, 512)    0           ['batch_normalization_9[0][0]',  \n",
      "                                                                  'leaky_re_lu_3[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_9 (LeakyReLU)      (None, 8, 8, 512)    0           ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 8, 8, 512)    0           ['leaky_re_lu_9[0][0]']          \n",
      "                                                                                                  \n",
      " conv2d_transpose_3 (Conv2DTran  (None, 16, 16, 128)  1048576    ['dropout_2[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 16, 16, 128)  512        ['conv2d_transpose_3[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_3 (Concatenate)    (None, 16, 16, 256)  0           ['batch_normalization_10[0][0]', \n",
      "                                                                  'leaky_re_lu_2[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_10 (LeakyReLU)     (None, 16, 16, 256)  0           ['concatenate_3[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 16, 16, 256)  0           ['leaky_re_lu_10[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_transpose_4 (Conv2DTran  (None, 32, 32, 64)  262144      ['dropout_3[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 32, 32, 64)  256         ['conv2d_transpose_4[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_4 (Concatenate)    (None, 32, 32, 128)  0           ['batch_normalization_11[0][0]', \n",
      "                                                                  'leaky_re_lu_1[0][0]']          \n",
      "                                                                                                  \n",
      " leaky_re_lu_11 (LeakyReLU)     (None, 32, 32, 128)  0           ['concatenate_4[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 32, 32, 128)  0           ['leaky_re_lu_11[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_transpose_5 (Conv2DTran  (None, 64, 64, 32)  65536       ['dropout_4[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 64, 64, 32)  128         ['conv2d_transpose_5[0][0]']     \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate_5 (Concatenate)    (None, 64, 64, 64)   0           ['batch_normalization_12[0][0]', \n",
      "                                                                  'leaky_re_lu[0][0]']            \n",
      "                                                                                                  \n",
      " leaky_re_lu_12 (LeakyReLU)     (None, 64, 64, 64)   0           ['concatenate_5[0][0]']          \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 64, 64, 64)   0           ['leaky_re_lu_12[0][0]']         \n",
      "                                                                                                  \n",
      " conv2d_transpose_6 (Conv2DTran  (None, 64, 64, 2)   2048        ['dropout_5[0][0]']              \n",
      " spose)                                                                                           \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 10,464,512\n",
      "Trainable params: 10,460,032\n",
      "Non-trainable params: 4,480\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the generator and generator optimizer\n",
    "generator = make_generator()\n",
    "\n",
    "# Beta1 to decrease importance of previous batches\n",
    "generator_optimizer = optimizers.Adam(2e-4,beta_1=0.5)\n",
    "generator.compile()\n",
    "generator.summary()\n",
    "#keras.utils.plot_model(generator,show_shapes=True,to_file='generator.png',dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_discriminator():\n",
    "\n",
    "    init = initializers.RandomNormal()\n",
    "\n",
    "    gray_input = layers.Input(shape=(64,64,1))\n",
    "    color_input = layers.Input(shape=(64,64,2))\n",
    "\n",
    "    # Gray and colored inputs are combined\n",
    "    concat_input = layers.concatenate([gray_input,color_input])\n",
    "\n",
    "    # Downsampling stack\n",
    "    down0 = downsampling(filters=64,stride=2,prev_layer=concat_input) # (64x64) -> (32x32)\n",
    "    down1 = downsampling(128,2,down0)        # (32x32) -> (16x16)\n",
    "    down2 = downsampling(256,2,down1)        # (16x16) -> (8x8)\n",
    "\n",
    "    # Model output is (8x8) with unbounded values (no activation)\n",
    "    model_output = layers.Conv2D(1,2,strides=1,padding='same',kernel_initializer=init,use_bias=False)(down2)\n",
    "\n",
    "    model = keras.Model(inputs=[gray_input,color_input],outputs=model_output)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(disc_output_generated,disc_output_real):\n",
    "\n",
    "    cross_entropy = losses.BinaryCrossentropy(from_logits=True,label_smoothing=0.1)\n",
    "\n",
    "    # Discriminator wants to classify real images as 1 and generated\n",
    "    # images as 0. Loss is the difference between the desired outputs\n",
    "    # and the actual outputs\n",
    "    real_loss = cross_entropy(tf.ones_like(disc_output_real),disc_output_real)\n",
    "    generated_loss = cross_entropy(tf.zeros_like(disc_output_generated),disc_output_generated)\n",
    "\n",
    "    total_loss = real_loss + generated_loss\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 64, 64, 1)]  0           []                               \n",
      "                                                                                                  \n",
      " input_3 (InputLayer)           [(None, 64, 64, 2)]  0           []                               \n",
      "                                                                                                  \n",
      " concatenate_6 (Concatenate)    (None, 64, 64, 3)    0           ['input_2[0][0]',                \n",
      "                                                                  'input_3[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 32, 32, 64)   3072        ['concatenate_6[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 32, 32, 64)  256         ['conv2d_7[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_13 (LeakyReLU)     (None, 32, 32, 64)   0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 16, 16, 128)  131072      ['leaky_re_lu_13[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 16, 16, 128)  512        ['conv2d_8[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_14 (LeakyReLU)     (None, 16, 16, 128)  0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 8, 8, 256)    524288      ['leaky_re_lu_14[0][0]']         \n",
      "                                                                                                  \n",
      " batch_normalization_15 (BatchN  (None, 8, 8, 256)   1024        ['conv2d_9[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " leaky_re_lu_15 (LeakyReLU)     (None, 8, 8, 256)    0           ['batch_normalization_15[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 8, 8, 1)      1024        ['leaky_re_lu_15[0][0]']         \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 661,248\n",
      "Trainable params: 660,352\n",
      "Non-trainable params: 896\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Make the discriminator and discriminator optimizer\n",
    "discriminator = make_discriminator()\n",
    "discriminator_optimizer = optimizers.Adam(2e-4)\n",
    "discriminator.compile()\n",
    "discriminator.summary()\n",
    "#keras.utils.plot_model(discriminator,show_shapes=True,to_file='discriminator.png',dpi=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(gray_channel,color_channels):\n",
    "\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
    "\n",
    "        # Generate a batch of fake images\n",
    "        generator_output = generator(gray_channel,training=True)\n",
    "\n",
    "        # Get discriminator output on real and generated images\n",
    "        disc_output_real = discriminator([gray_channel,color_channels],training=True)\n",
    "        disc_output_generated = discriminator([gray_channel,generator_output],training=True)\n",
    "\n",
    "        # Calculate loss for generator and discriminator based on discriminator outputs\n",
    "        gen_loss, adversarial_loss, mse_loss = generator_loss(disc_output_generated,generator_output,color_channels)\n",
    "        disc_loss = discriminator_loss(disc_output_generated,disc_output_real)\n",
    "\n",
    "    # Calculate generator gradients and train generator\n",
    "    generator_gradients = gen_tape.gradient(gen_loss,generator.trainable_variables)\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,generator.trainable_variables))\n",
    "\n",
    "    # Calculate disciminator gradients and train discriminator\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,discriminator.trainable_variables)\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,discriminator.trainable_variables))\n",
    "\n",
    "    # Update tensorboard losses\n",
    "    gen_loss_tracker(gen_loss)\n",
    "    gen_adv_tracker(adversarial_loss)\n",
    "    gen_mse_tracker(mse_loss)\n",
    "    disc_loss_tracker(disc_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(epochs,dataset):\n",
    "    \n",
    "    step_counter = 0\n",
    "\n",
    "    # Progress bar/tracking\n",
    "    for _ in tqdm(range(epochs)):\n",
    "\n",
    "        for gray_channel,color_channels in dataset:\n",
    "            train_step(gray_channel,color_channels)\n",
    "\n",
    "            # Tensorboard logging for training\n",
    "            with summary_writer.as_default():\n",
    "                tf.summary.scalar('Generator_loss',gen_loss_tracker.result(),step=step_counter)\n",
    "                tf.summary.scalar('Generator_adversarial_loss',gen_adv_tracker.result(),step=step_counter)\n",
    "                tf.summary.scalar('Generator_mse_loss',gen_mse_tracker.result(),step=step_counter)\n",
    "                tf.summary.scalar('Discriminator_loss',disc_loss_tracker.result(),step=step_counter)\n",
    "            \n",
    "            gen_loss_tracker.reset_states()\n",
    "            gen_adv_tracker.reset_states()\n",
    "            gen_mse_tracker.reset_states()\n",
    "            disc_loss_tracker.reset_states()\n",
    "            step_counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_model(epochs=200,dataset=train_dataset)\n",
    "#generator.save('models/dusty/generator.h5')\n",
    "#discriminator.save('models/dusty/discriminator.h5')\n",
    "dusty_gen = keras.models.load_model('models/1-9-23/dusty/generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty lists for the frames for 3 gifs\n",
    "train_folder = '../shows/episode3/'\n",
    "save_folder = 'resources/video/'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Train Results</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_frames = []\n",
    "colorized_frames = []\n",
    "original_frames = []\n",
    "\n",
    "# 256 Frames is roughly 30 seconds of video\n",
    "train_batch = utils.image_loader(directory=train_folder,\n",
    "    batch_size=256,training=False,sort_files=True).__getitem__(2)\n",
    "\n",
    "train_output = dusty_gen(train_batch[0],training=False)\n",
    "\n",
    "for frame_number, gray_frame in enumerate(train_batch[0]):\n",
    "\n",
    "    grayscale_dummy_color = np.dstack([np.zeros_like(gray_frame),\n",
    "        np.zeros_like(gray_frame)])\n",
    "\n",
    "    grayscale_frames.append(utils.lab_to_rgb_combine_channels(\n",
    "        l_channel=gray_frame,\n",
    "        ab_channels=grayscale_dummy_color\n",
    "    ))\n",
    "\n",
    "    colorized_frames.append(utils.lab_to_rgb_combine_channels(\n",
    "        l_channel=gray_frame,\n",
    "        ab_channels=train_output[frame_number]\n",
    "    ))\n",
    "\n",
    "    original_frames.append(utils.lab_to_rgb_combine_channels(\n",
    "        l_channel=gray_frame,\n",
    "        ab_channels = train_batch[1][frame_number]\n",
    "    ))\n",
    "\n",
    "with imageio.get_writer(save_folder + 'train_grayscale.mp4',mode='I',fps=8,quality=10) as writer:\n",
    "    for frame in grayscale_frames:\n",
    "        writer.append_data(frame)\n",
    "\n",
    "with imageio.get_writer(save_folder + 'train_colorized.mp4',mode='I',fps=8,quality=10) as writer:\n",
    "    for frame in colorized_frames:\n",
    "        writer.append_data(frame)\n",
    "\n",
    "with imageio.get_writer(save_folder + 'train_original.mp4',mode='I',fps=8,quality=10) as writer:\n",
    "    for frame in original_frames:\n",
    "        writer.append_data(frame)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Grayscale</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"resources/video/train_grayscale.mp4\" controls  width=\"256\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('resources/video/train_grayscale.mp4',width=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Colorized using Model</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"resources/video/train_colorized.mp4\" controls  width=\"256\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('resources/video/train_colorized.mp4',width=256)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Original Color</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"resources/video/train_original.mp4\" controls  width=\"256\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video('resources/video/train_original.mp4',width=256)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6 (main, Nov 14 2022, 16:10:14) [GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
